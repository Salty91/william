{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93b7418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 23:45:35.390745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-31 23:45:35.390798: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import data_utils\n",
    "# from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from keras.utils.layer_utils import print_summary\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13779829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b41e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_utils.pad_sequences(train_data, MAXLEN)\n",
    "test_data = data_utils.pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2657f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d026f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02807109-a29f-4c22-b616-5ca54750d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2e94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 60s 92ms/step - loss: 0.4215 - acc: 0.8053 - val_loss: 0.2816 - val_acc: 0.8842\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 57s 91ms/step - loss: 0.2410 - acc: 0.9092 - val_loss: 0.2933 - val_acc: 0.8932\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 57s 91ms/step - loss: 0.1862 - acc: 0.9319 - val_loss: 0.2901 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 57s 92ms/step - loss: 0.1532 - acc: 0.9457 - val_loss: 0.3160 - val_acc: 0.8886\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 57s 92ms/step - loss: 0.1323 - acc: 0.9539 - val_loss: 0.3306 - val_acc: 0.8856\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 59s 95ms/step - loss: 0.1184 - acc: 0.9597 - val_loss: 0.3168 - val_acc: 0.8888\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.1005 - acc: 0.9662 - val_loss: 0.3668 - val_acc: 0.8838\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.0874 - acc: 0.9712 - val_loss: 0.3433 - val_acc: 0.8922\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.0799 - acc: 0.9735 - val_loss: 0.4114 - val_acc: 0.8608\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.0700 - acc: 0.9769 - val_loss: 0.3990 - val_acc: 0.8850\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
    "    \n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3e2715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/charlie-chin/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/charlie-chin/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/home/charlie-chin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f269b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('/home/charlie-chin/saved_model.pb')\n",
    "\n",
    "# model = tf.saved_model.load('/home/charlie-chin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee39dcc-2083-42ae-8ea7-86d0921317a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to h5\n",
    "\n",
    "# model.save('model_name.h5')\n",
    "\n",
    "model = keras.models.load_model('model_name.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e34964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 27s 32ms/step - loss: 0.4966 - acc: 0.8536\n",
      "[0.4965744912624359, 0.8536400198936462]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dfd054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0   12   17   13   40  424  477   35 7110  477]\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
    "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "  return data_utils.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "text = \"That movie was just absolutely amazing, so freaking amazing\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5335cd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just absolutely amazing so freaking amazing\n"
     ]
    }
   ],
   "source": [
    "# while were at it lets make a decode function\n",
    "\n",
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "      if num != PAD:\n",
    "        text += reverse_word_index[num] + \" \"\n",
    "\n",
    "    return text[:-1]\n",
    "  \n",
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea2274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 439ms/step\n",
      "[0.79718405]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[0.40643787]\n"
     ]
    }
   ],
   "source": [
    "# now time to make a prediction\n",
    "\n",
    "def predict(text):\n",
    "  encoded_text = encode_text(text)\n",
    "  pred = np.zeros((1,250))\n",
    "  pred[0] = encoded_text\n",
    "  result = model.predict(pred) \n",
    "  print(result[0])\n",
    "\n",
    "positive_review = \"That movie was terrible!\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"that movie really fucking sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292aced7-9a93-48a1-9078-c3df3cc94a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_file = tf.keras.utils.get_file('factotum.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a4b0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open('/home/charlie-chin/factotum.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# Chinaski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59ad517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3660f8a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae25037-ad95-499b-9bb6-5cbe376a5ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us\n"
     ]
    }
   ],
   "source": [
    "# lets look at how part of our text is encoded\n",
    "print(\"Text:\", text[:300])\n",
    "# print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca29f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "  return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28966ac1-6c84-4da4-a11e-d2ad6492dacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fad7e93-9d4d-4eb5-b47a-15e394239f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18055818-04e1-4173-840c-18a46143637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d57fd17-3ea4-4047-b5a2-59e0fd012ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "  try:\n",
    "    ints = ints.numpy()\n",
    "  except:\n",
    "    pass\n",
    "  return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322be952-895f-42c9-ae70-1a687a5b306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 23:46:05.203115: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-31 23:46:05.203175: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Lenovo-C540): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100  # length of sequence for a training example\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc515f58-44e7-4bb1-9d1a-c1f82b5005ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86be25fd-4636-457c-a3b6-82e081ae4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):  # for the example: hello\n",
    "    input_text = chunk[:-1]  # hell\n",
    "    target_text = chunk[1:]  # ello\n",
    "    return input_text, target_text  # hell, ello\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83cf59a-ce03-4394-bd74-76a8259a42af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you \n",
      "\n",
      "OUTPUT\n",
      "re all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "  print(\"\\n\\nEXAMPLE\\n\")\n",
    "  print(\"INPUT\")\n",
    "  print(int_to_text(x))\n",
    "  print(\"\\nOUTPUT\")\n",
    "  print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c44246-ceef-43cf-8750-5ba6d06eb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25703b9-41df-49cf-ad46-4c1268982ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ac334b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e37c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(data.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2610eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 23:46:11.704364: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26214400 exceeds 10% of free system memory.\n",
      "2022-07-31 23:46:11.709493: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26214400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "#     global example_batch_predictions\n",
    "    example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814404e6-e8d1-41bd-b507-0b5a41120932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[-2.6581415e-03  2.3636459e-03 -3.8874033e-03 ...  1.6289169e-03\n",
      "    2.9568605e-03  7.6596066e-04]\n",
      "  [-1.8038116e-03 -1.4459093e-03  9.7385002e-04 ...  4.1218735e-03\n",
      "   -1.5728548e-04  4.5654075e-03]\n",
      "  [-4.6740384e-03  1.2562384e-03 -3.5524417e-03 ...  4.8077861e-03\n",
      "    3.4265940e-03  3.9500310e-03]\n",
      "  ...\n",
      "  [-1.7590048e-03  1.3837002e-03 -6.8057328e-05 ... -1.0800315e-03\n",
      "   -6.1123148e-03  3.1818745e-03]\n",
      "  [-3.0875108e-03  3.0013628e-03 -4.9328902e-03 ...  1.6749259e-03\n",
      "   -2.2890996e-03  2.7728286e-03]\n",
      "  [-2.1679816e-03  2.0522121e-03 -5.1994030e-03 ...  1.0803761e-04\n",
      "   -6.7133261e-03  1.3324291e-03]]\n",
      "\n",
      " [[ 6.5799756e-04  4.6394314e-04  9.9630211e-05 ... -2.3092623e-03\n",
      "   -3.8308310e-03 -4.2605179e-04]\n",
      "  [-9.1999471e-03 -9.4744074e-04 -3.1420665e-03 ... -6.1509991e-03\n",
      "   -5.0447872e-03 -6.5396908e-03]\n",
      "  [-5.8108978e-03  1.2550820e-03  3.0525093e-04 ... -6.0491143e-03\n",
      "   -2.0101545e-03 -2.7650197e-03]\n",
      "  ...\n",
      "  [-3.2898542e-03 -6.7514810e-04 -1.8008612e-04 ...  4.7019143e-03\n",
      "   -4.6909051e-03  8.5417712e-03]\n",
      "  [-5.3007398e-03  1.6012285e-03 -5.0331187e-03 ...  6.4382278e-03\n",
      "    6.1443495e-04  7.4799396e-03]\n",
      "  [-1.5436506e-02 -5.8459584e-04 -8.5179256e-03 ...  1.1828342e-03\n",
      "   -1.4798196e-03  2.9371667e-04]]\n",
      "\n",
      " [[-4.0636314e-03  1.3207407e-03  3.1635014e-03 ... -1.7855479e-03\n",
      "   -2.9558465e-03  3.4822221e-03]\n",
      "  [-2.1830592e-03  9.4843999e-04  2.1011971e-03 ... -3.9498303e-03\n",
      "   -6.5318793e-03  2.8022474e-03]\n",
      "  [-3.6293366e-03  2.6184586e-03 -2.6564177e-03 ... -7.8633009e-04\n",
      "   -2.4635191e-03  2.5917387e-03]\n",
      "  ...\n",
      "  [-8.6852312e-03  3.7993235e-03 -6.7409240e-03 ...  4.0761922e-03\n",
      "    6.3062240e-03  7.7541932e-03]\n",
      "  [-3.2667976e-03  1.4742364e-02 -1.0666685e-02 ...  1.9160798e-03\n",
      "    1.3606017e-03  5.2383449e-03]\n",
      "  [-5.3995186e-03  1.1378341e-02 -8.0545442e-03 ...  3.8536782e-03\n",
      "    7.3322561e-04  7.3320461e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.5133213e-03  1.7051422e-03  1.8133903e-03 ...  3.3935648e-04\n",
      "   -7.8483822e-04  2.5496841e-03]\n",
      "  [-4.9464628e-03  2.3414739e-03  2.8004791e-03 ... -5.7318015e-04\n",
      "   -3.3413945e-03  9.6543990e-03]\n",
      "  [-9.5854700e-03  3.4096516e-03  2.6704289e-04 ...  1.0726899e-03\n",
      "   -1.0747380e-03  6.5710559e-03]\n",
      "  ...\n",
      "  [-9.9327024e-03  4.4059535e-03 -1.7205833e-03 ... -6.4244661e-03\n",
      "    9.6685626e-04  8.5804495e-04]\n",
      "  [-6.9409581e-03 -6.3049817e-04  9.5376512e-04 ... -2.3590149e-03\n",
      "    1.0586460e-05 -3.2463332e-04]\n",
      "  [-1.4334994e-03 -2.8135946e-03  5.6671668e-03 ... -7.7888882e-04\n",
      "    3.3896882e-04 -1.8228251e-03]]\n",
      "\n",
      " [[-3.4036867e-03 -4.5797620e-03  4.2940918e-03 ...  1.0456564e-03\n",
      "   -1.7132061e-03 -3.3305390e-03]\n",
      "  [-3.7254286e-03  1.9760467e-03  3.4382187e-03 ... -1.3221591e-03\n",
      "   -3.4835453e-03 -6.6137230e-03]\n",
      "  [-4.6775118e-03  4.3639597e-03 -7.0135389e-04 ...  1.3575247e-03\n",
      "    1.3572890e-03 -3.3843147e-03]\n",
      "  ...\n",
      "  [-1.1508459e-02 -2.5726520e-03 -9.2122294e-03 ... -4.5063053e-03\n",
      "    8.1489841e-04  4.3442743e-03]\n",
      "  [-1.1338688e-02 -2.1710806e-04 -1.0994095e-02 ... -1.4410140e-03\n",
      "    5.8185738e-03  4.2714989e-03]\n",
      "  [-8.2475450e-03  2.6877697e-03 -7.0018778e-03 ... -2.7473297e-03\n",
      "    1.4265985e-03 -1.9314107e-03]]\n",
      "\n",
      " [[ 8.1896258e-04 -3.5613989e-03  3.3503368e-03 ...  8.9931861e-04\n",
      "   -9.5534674e-04 -7.3970226e-04]\n",
      "  [-2.3808165e-03 -1.3528726e-03  4.5273919e-04 ... -7.0269918e-03\n",
      "   -3.6468520e-04 -2.2021132e-03]\n",
      "  [-2.7443143e-04 -3.9323382e-03  5.4917680e-03 ... -2.9960310e-03\n",
      "   -2.1986491e-03  3.2064307e-03]\n",
      "  ...\n",
      "  [-8.3172638e-03 -2.5442096e-03 -1.3443313e-03 ...  2.0771261e-04\n",
      "    8.0323657e-03 -2.5729563e-03]\n",
      "  [-5.9317518e-03 -6.1244564e-03  1.6937214e-03 ...  3.1262436e-03\n",
      "    4.6341191e-03  2.7179206e-03]\n",
      "  [-8.8900179e-03 -6.6355942e-03 -7.8635234e-03 ...  7.7182157e-03\n",
      "   -6.0228165e-05  6.4744800e-03]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n",
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aa207a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[-2.6581415e-03  2.3636459e-03 -3.8874033e-03 ...  1.6289169e-03\n",
      "   2.9568605e-03  7.6596066e-04]\n",
      " [-1.8038116e-03 -1.4459093e-03  9.7385002e-04 ...  4.1218735e-03\n",
      "  -1.5728548e-04  4.5654075e-03]\n",
      " [-4.6740384e-03  1.2562384e-03 -3.5524417e-03 ...  4.8077861e-03\n",
      "   3.4265940e-03  3.9500310e-03]\n",
      " ...\n",
      " [-1.7590048e-03  1.3837002e-03 -6.8057328e-05 ... -1.0800315e-03\n",
      "  -6.1123148e-03  3.1818745e-03]\n",
      " [-3.0875108e-03  3.0013628e-03 -4.9328902e-03 ...  1.6749259e-03\n",
      "  -2.2890996e-03  2.7728286e-03]\n",
      " [-2.1679816e-03  2.0522121e-03 -5.1994030e-03 ...  1.0803761e-04\n",
      "  -6.7133261e-03  1.3324291e-03]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# lets examine one prediction\n",
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)\n",
    "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "582aca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[-2.6581415e-03  2.3636459e-03 -3.8874033e-03  4.2635123e-03\n",
      " -2.6893173e-04 -1.5991735e-03 -1.9117077e-03 -8.9802977e-04\n",
      "  5.0622793e-03 -2.8919349e-03 -4.1993419e-03  3.1710120e-03\n",
      " -3.0989121e-03 -1.1679454e-03 -4.4322419e-03 -2.9219007e-03\n",
      "  4.1865157e-03 -2.4056223e-03  6.0539681e-04  3.3391153e-03\n",
      " -9.2532905e-04  1.7211623e-03 -1.5615821e-03 -4.3682791e-03\n",
      " -3.0893236e-03  4.0713593e-04 -6.5425062e-04  2.0946499e-03\n",
      " -4.8261764e-04 -9.8841521e-04  4.6673855e-03  5.8853757e-03\n",
      "  5.0863293e-03  2.7425901e-04  2.9035306e-03 -1.9751466e-03\n",
      " -2.4468405e-05 -4.2793900e-03 -3.1805355e-03 -2.3184998e-03\n",
      " -6.3780742e-04 -5.0550350e-03  8.2702748e-04 -2.9024163e-03\n",
      " -1.1926051e-03 -4.3999441e-03  1.1473444e-03 -1.2847086e-03\n",
      " -5.6837257e-03  1.2848447e-03 -1.7764760e-03  2.5863461e-03\n",
      "  3.5549630e-05 -3.8469376e-03 -4.5221578e-03  4.2800969e-03\n",
      " -2.7014217e-03 -6.8631279e-03  7.0651062e-03  3.0789394e-03\n",
      "  6.1672414e-05 -1.4926331e-03  1.6289169e-03  2.9568605e-03\n",
      "  7.6596066e-04], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# and finally well look at a prediction at the first timestep\n",
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)\n",
    "# and of course its 65 values representing the probabillity of each character occuring next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec337da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"jPtCNAX.ms3,ZyWrtYtUpKUQ:APX\\nUa: hu.KXUiW:f'EBLc$h,wdsq bgFT'v;rXHelHoKEKCaB,CTFoQlvAYmWP$KnqS?ez,Jj\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars  # and this is what the model predicted for training sequence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397cc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63390f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c1de2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = '/home/charlie-chin/william_model/training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adde4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6878d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('/home/charlie-chin/william_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7880a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('model_name.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "379ad11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/home/charlie-chin/william_model', custom_objects={'loss':loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2421a531-d922-40b7-a86d-760d8ae9d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73fe1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94ad3db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7a1869c160>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_num = 10\n",
    "# model.load_weights(tf.train.load_checkpoint(\"./william_model/training_checkpoints/ckpt_\"))\n",
    "# model.load_weights(tf.train.Checkpoint(\"/home/charlie-chin/william_model/training_checkpoints/ckpt_\" + str(checkpoint_num)+\".data-00000-of-00001\"))\n",
    "model.load_weights(\"/home/charlie-chin/william_model/training_checkpoints/ckpt_\" + str(checkpoint_num))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cea419",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b970e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18feca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 800\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "    \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6985e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a starting string:  juliette\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "julietter'd by,\n",
      "I live in lives 'God send furbroa and warwick?\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Let him desister; and tells him in the steel\n",
      "Whis master's head,\n",
      "And give his love and speechless heavior spent\n",
      "That would not pey you without unknown:\n",
      "Indued, sometime master, thou hast sandsto perugance\n",
      "\n",
      "ROMEO:\n",
      "Who's that a journey? for your bloody breast?\n",
      "What still-meant cannot charge thee all of garteness,\n",
      "And grew thy body scops: a' 'twas chief, but\n",
      "most vonours that goes, and therefore fire,\n",
      "And it is, crutling somewhat very oddenance\n",
      "Is talk, the fire did not be seen then trage his enemies.\n",
      "Alack, my Loed Gloreo, and you shall peck,\n",
      "And now my lords, lift on their death in about chaste,\n",
      "And brother Walting now by necesses more\n",
      "Of when you having only here call it,\n",
      "That you are set in standers kind, that I shoul\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
